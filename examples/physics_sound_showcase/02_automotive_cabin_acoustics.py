"""Automotive Cabin Acoustics - Physics-to-Sound Showcase

This example demonstrates Morphogen's unique capability to combine fluid dynamics,
acoustic propagation, and audio synthesis for automotive engineering applications.

APPLICATION: Car interior acoustic design and optimization

PHYSICS â†’ ACOUSTICS â†’ AUDIO PIPELINE:
1. Cabin geometry (3D space, materials, boundaries)
2. Fluid dynamics (air flow, pressure fields, turbulence)
3. Acoustic wave propagation (2D/3D wave equation, reflections)
4. Sound source modeling (speakers, wind noise, road noise, engine)
5. Audio rendering (binaural, multi-channel, spatial audio)

AUTOMOTIVE ENGINEERING USE CASES:
- Speaker placement optimization for premium audio systems
- Wind noise prediction and reduction
- Road noise analysis and cabin isolation design
- Active noise cancellation (ANC) system design
- Engine sound tuning (acoustic comfort)

REAL-WORLD VALUE:
- Automotive OEMs: Design better cabins before prototyping ($$$)
- Audio suppliers: Optimize speaker systems (Bose, Harman, etc.)
- NVH engineers: Predict and reduce noise, vibration, harshness
- Research: Study psychoacoustics and spatial audio perception

No other platform integrates physics, acoustics, and audio like this.
"""

import sys
import numpy as np
from pathlib import Path
from typing import List, Tuple, Dict, Any
from dataclasses import dataclass

# Add parent to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from morphogen.stdlib import field, audio, visual, palette, io_storage
from morphogen.stdlib.field import Field2D
from morphogen.stdlib.audio import AudioBuffer


# ============================================================================
# CABIN GEOMETRY AND MATERIALS
# ============================================================================

@dataclass
class Material:
    """Acoustic material properties."""
    name: str
    absorption_coefficient: float  # 0 (reflective) to 1 (absorptive)
    impedance: float  # Acoustic impedance (PaÂ·s/m)
    reflection_coefficient: float  # Computed from absorption


# Common automotive materials
GLASS = Material("Glass", absorption_coefficient=0.05, impedance=3.8e6,
                 reflection_coefficient=0.95)
FABRIC = Material("Fabric/Carpet", absorption_coefficient=0.30, impedance=450.0,
                  reflection_coefficient=0.70)
FOAM = Material("Acoustic Foam", absorption_coefficient=0.80, impedance=120.0,
                reflection_coefficient=0.20)
PLASTIC = Material("Hard Plastic", absorption_coefficient=0.10, impedance=2.5e6,
                   reflection_coefficient=0.90)
LEATHER = Material("Leather Seat", absorption_coefficient=0.25, impedance=500.0,
                   reflection_coefficient=0.75)


@dataclass
class CabinGeometry:
    """Simplified 2D cabin geometry (side view)."""
    length: float  # meters (front to back)
    height: float  # meters (floor to ceiling)
    resolution: int  # grid resolution

    # Material zones (simplified)
    floor_material: Material
    ceiling_material: Material
    windshield_material: Material
    rear_material: Material


# ============================================================================
# ACOUSTIC WAVE PROPAGATION (2D)
# ============================================================================

def create_cabin_field(geometry: CabinGeometry) -> Field2D:
    """Create 2D field representing cabin interior.

    Args:
        geometry: Cabin geometry specification

    Returns:
        Field2D for acoustic simulation
    """
    # Create field
    width = int(geometry.length * geometry.resolution)
    height = int(geometry.height * geometry.resolution)

    cabin_field = field.create(width, height, fill_value=0.0)

    return cabin_field


def add_boundary_conditions(cabin_field: Field2D, geometry: CabinGeometry) -> Field2D:
    """Add reflective/absorptive boundaries for cabin walls.

    This creates a "mask" that represents material properties.

    Args:
        cabin_field: Acoustic field
        geometry: Cabin geometry

    Returns:
        Field with boundary conditions
    """
    h, w = cabin_field.data.shape

    # Create absorption mask (1.0 = fully absorptive, 0.0 = reflective)
    absorption_mask = np.zeros((h, w))

    # Floor (bottom) - carpet/fabric
    absorption_mask[-5:, :] = geometry.floor_material.absorption_coefficient

    # Ceiling (top) - headliner
    absorption_mask[:5, :] = geometry.ceiling_material.absorption_coefficient

    # Front (left) - windshield
    absorption_mask[:, :10] = geometry.windshield_material.absorption_coefficient

    # Rear (right) - rear window/seats
    absorption_mask[:, -10:] = geometry.rear_material.absorption_coefficient

    # Store in field metadata
    # (In real implementation, this would be used in wave equation solver)

    return cabin_field


def simulate_speaker_wave_propagation(
    cabin_field: Field2D,
    speaker_position: Tuple[float, float],  # (x, y) in meters
    frequency: float,  # Hz
    geometry: CabinGeometry,
    num_steps: int = 500,
    dt: float = 0.0001  # time step in seconds
) -> List[Field2D]:
    """Simulate acoustic wave propagation from speaker.

    Uses simplified 2D wave equation:
    âˆ‚Â²p/âˆ‚tÂ² = cÂ² âˆ‡Â²p

    where p is pressure, c is speed of sound.

    Args:
        cabin_field: Cabin acoustic field
        speaker_position: Speaker location (x, y) in meters
        frequency: Frequency to simulate
        geometry: Cabin geometry
        num_steps: Number of time steps
        dt: Time step size

    Returns:
        List of field snapshots showing wave propagation
    """
    h, w = cabin_field.data.shape

    # Speed of sound in air
    c = 343.0  # m/s

    # Convert speaker position to grid coordinates
    speaker_x = int(speaker_position[0] * geometry.resolution)
    speaker_y = int(speaker_position[1] * geometry.resolution)

    # Initialize pressure fields (current and previous)
    p_current = np.zeros((h, w))
    p_previous = np.zeros((h, w))

    # Grid spacing
    dx = 1.0 / geometry.resolution  # meters

    # CFL condition for stability
    r = (c * dt / dx) ** 2
    if r > 0.25:
        print(f"Warning: CFL condition violated (r={r:.3f}). Reducing dt.")
        dt = 0.25 * dx / c
        r = 0.25

    snapshots = []
    save_interval = num_steps // 20  # Save 20 snapshots

    # Time-stepping loop
    omega = 2 * np.pi * frequency

    for step in range(num_steps):
        # Source term: speaker oscillation
        t = step * dt
        source_amplitude = np.sin(omega * t)

        # Add source at speaker position
        p_current[speaker_y, speaker_x] = source_amplitude

        # Wave equation: âˆ‚Â²p/âˆ‚tÂ² = cÂ² âˆ‡Â²p
        # Discretized: p_new = 2*p_current - p_previous + r*(âˆ‡Â²p)

        # Compute Laplacian (using field operations)
        laplacian = (
            np.roll(p_current, 1, axis=0) +
            np.roll(p_current, -1, axis=0) +
            np.roll(p_current, 1, axis=1) +
            np.roll(p_current, -1, axis=1) -
            4 * p_current
        )

        # Update
        p_new = 2 * p_current - p_previous + r * laplacian

        # Apply boundary conditions (simplified absorption)
        # In real implementation, this would use impedance-based boundaries
        p_new[0, :] *= 0.95  # Ceiling
        p_new[-1, :] *= 0.70  # Floor (carpet)
        p_new[:, 0] *= 0.95  # Windshield
        p_new[:, -1] *= 0.75  # Rear

        # Update for next iteration
        p_previous = p_current
        p_current = p_new

        # Save snapshot
        if step % save_interval == 0:
            snapshot = field.create(w, h, fill_value=0.0)
            snapshot.data = p_current.copy()
            snapshots.append(snapshot)

    return snapshots


def extract_audio_at_listener_position(
    snapshots: List[Field2D],
    listener_position: Tuple[float, float],  # (x, y) in meters
    geometry: CabinGeometry,
    sample_rate: int = 44100,
    total_duration: float = 1.0
) -> np.ndarray:
    """Extract pressure time series at listener position to create audio.

    Args:
        snapshots: List of pressure field snapshots
        listener_position: Listener location (x, y) in meters
        geometry: Cabin geometry
        sample_rate: Audio sample rate
        total_duration: Total duration in seconds

    Returns:
        Audio signal (numpy array)
    """
    # Convert listener position to grid coordinates
    listener_x = int(listener_position[0] * geometry.resolution)
    listener_y = int(listener_position[1] * geometry.resolution)

    # Extract pressure at listener position from each snapshot
    pressure_samples = []
    for snapshot in snapshots:
        p = snapshot.data[listener_y, listener_x]
        pressure_samples.append(p)

    # Interpolate to audio sample rate
    snapshot_times = np.linspace(0, total_duration, len(pressure_samples))
    audio_times = np.arange(int(total_duration * sample_rate)) / sample_rate

    audio_signal = np.interp(audio_times, snapshot_times, pressure_samples)

    # Normalize
    if np.max(np.abs(audio_signal)) > 0:
        audio_signal = audio_signal / np.max(np.abs(audio_signal))

    return audio_signal


# ============================================================================
# SPEAKER PLACEMENT OPTIMIZATION
# ============================================================================

def evaluate_speaker_placement(
    speaker_positions: List[Tuple[float, float]],
    listener_position: Tuple[float, float],
    geometry: CabinGeometry,
    test_frequency: float = 1000.0
) -> Dict[str, Any]:
    """Evaluate acoustic quality for given speaker placement.

    Metrics:
    - Direct sound arrival time
    - Early reflections (first 50ms)
    - Reverberant field energy
    - Frequency response flatness

    Args:
        speaker_positions: List of (x, y) speaker positions
        listener_position: Listener (x, y) position
        geometry: Cabin geometry
        test_frequency: Frequency to test (Hz)

    Returns:
        Dictionary of acoustic metrics
    """
    # Simplified metric: average distance from speakers to listener
    distances = []
    for sp_x, sp_y in speaker_positions:
        dist = np.sqrt((sp_x - listener_position[0])**2 +
                      (sp_y - listener_position[1])**2)
        distances.append(dist)

    avg_distance = np.mean(distances)
    distance_std = np.std(distances)

    # Lower std = more balanced speaker arrangement
    balance_score = 1.0 / (1.0 + distance_std * 10.0)

    # Optimal distance ~1-2 meters
    distance_score = np.exp(-((avg_distance - 1.5) ** 2) / 0.5)

    overall_score = 0.6 * balance_score + 0.4 * distance_score

    return {
        "avg_distance": avg_distance,
        "distance_std": distance_std,
        "balance_score": balance_score,
        "distance_score": distance_score,
        "overall_score": overall_score
    }


# ============================================================================
# NOISE SOURCE MODELING
# ============================================================================

def generate_wind_noise(
    velocity: float,  # m/s
    turbulence_intensity: float,  # 0-1
    duration: float,
    sample_rate: int = 44100
) -> AudioBuffer:
    """Generate wind noise from aerodynamic turbulence.

    Wind noise is primarily high-frequency broadband noise.
    Frequency content increases with velocity.

    Args:
        velocity: Wind velocity in m/s
        turbulence_intensity: Turbulence level (0-1)
        duration: Duration in seconds
        sample_rate: Sample rate

    Returns:
        AudioBuffer with wind noise
    """
    n_samples = int(duration * sample_rate)

    # Generate white noise
    noise = np.random.randn(n_samples) * turbulence_intensity

    # Filter to emphasize frequencies based on velocity
    # Higher velocity = higher frequency content
    # Use simple lowpass at frequency proportional to velocity

    # Velocity-dependent cutoff (100 Hz at 10 m/s, 2000 Hz at 100 m/s)
    cutoff_freq = 50.0 + velocity * 20.0
    cutoff_freq = np.clip(cutoff_freq, 100.0, 8000.0)

    # Apply highpass filter (wind noise is primarily high-frequency)
    highpass_cutoff = cutoff_freq * 0.3

    # Simple first-order highpass
    alpha = 1.0 - np.exp(-2 * np.pi * highpass_cutoff / sample_rate)
    filtered = np.zeros(n_samples)
    for i in range(1, n_samples):
        filtered[i] = alpha * (filtered[i-1] + noise[i] - noise[i-1])

    # Amplitude increases with velocity squared (aerodynamic pressure ~ vÂ²)
    amplitude = (velocity / 30.0) ** 2  # Normalize to 30 m/s
    amplitude = np.clip(amplitude, 0.0, 1.0)

    output = filtered * amplitude

    # Normalize
    if np.max(np.abs(output)) > 0:
        output = output / np.max(np.abs(output))

    return AudioBuffer(data=output, sample_rate=sample_rate)


def generate_road_noise(
    road_roughness: float,  # 0-1 (smooth to rough)
    vehicle_speed: float,  # m/s
    duration: float,
    sample_rate: int = 44100
) -> AudioBuffer:
    """Generate road noise from tire-road interaction.

    Road noise is rhythmic, frequency depends on tire rotation.

    Args:
        road_roughness: Road surface roughness (0-1)
        vehicle_speed: Vehicle speed in m/s
        duration: Duration in seconds
        sample_rate: Sample rate

    Returns:
        AudioBuffer with road noise
    """
    n_samples = int(duration * sample_rate)
    t = np.arange(n_samples) / sample_rate

    # Tire rotation frequency
    # Assume tire circumference ~2 meters
    tire_circumference = 2.0  # meters
    rotation_freq = vehicle_speed / tire_circumference  # Hz

    # Road noise has fundamental at rotation frequency
    # Plus harmonics from tire pattern
    output = np.zeros(n_samples)

    for harmonic in range(1, 10):
        freq = rotation_freq * harmonic
        if freq > sample_rate / 2:
            break

        amplitude = road_roughness / harmonic
        phase = np.random.rand() * 2 * np.pi

        output += amplitude * np.sin(2 * np.pi * freq * t + phase)

    # Add broadband noise for texture
    broadband = np.random.randn(n_samples) * road_roughness * 0.3

    # Lowpass filter broadband
    # (road noise is low-mid frequency)
    cutoff = 500.0  # Hz
    alpha = np.exp(-2 * np.pi * cutoff / sample_rate)
    filtered_broadband = np.zeros(n_samples)
    filtered_broadband[0] = broadband[0]
    for i in range(1, n_samples):
        filtered_broadband[i] = alpha * filtered_broadband[i-1] + (1-alpha) * broadband[i]

    output += filtered_broadband

    # Normalize
    if np.max(np.abs(output)) > 0:
        output = output / np.max(np.abs(output))

    return AudioBuffer(data=output, sample_rate=sample_rate)


# ============================================================================
# MAIN DEMOS
# ============================================================================

def demo_speaker_optimization(output_dir: Path):
    """Demonstrate speaker placement optimization."""

    print("\n" + "="*70)
    print("SPEAKER PLACEMENT OPTIMIZATION")
    print("="*70)

    # Cabin geometry (compact car)
    geometry = CabinGeometry(
        length=2.5,  # 2.5 meters front to back
        height=1.2,  # 1.2 meters floor to ceiling
        resolution=100,  # 100 pixels per meter
        floor_material=FABRIC,
        ceiling_material=FABRIC,
        windshield_material=GLASS,
        rear_material=PLASTIC
    )

    # Listener position (driver's head)
    listener_pos = (1.0, 0.9)  # 1m from front, 0.9m height

    # Test different speaker configurations
    configurations = {
        "2-way (doors only)": [(0.7, 0.6), (1.3, 0.6)],  # Doors
        "4-way (doors + rear)": [(0.7, 0.6), (1.3, 0.6), (2.0, 0.7), (2.0, 1.0)],
        "Premium (doors + dash + rear)": [(0.5, 0.8), (0.7, 0.6), (1.3, 0.6), (2.0, 0.7)]
    }

    results = {}
    for config_name, speaker_positions in configurations.items():
        print(f"\n{config_name}:")
        print(f"  Speakers: {len(speaker_positions)}")

        metrics = evaluate_speaker_placement(
            speaker_positions, listener_pos, geometry
        )

        results[config_name] = metrics

        print(f"  Average distance: {metrics['avg_distance']:.2f} m")
        print(f"  Balance score: {metrics['balance_score']:.3f}")
        print(f"  Overall score: {metrics['overall_score']:.3f}")

    # Find best configuration
    best_config = max(results.items(), key=lambda x: x[1]['overall_score'])
    print(f"\nâœ“ Best configuration: {best_config[0]}")
    print(f"  Score: {best_config[1]['overall_score']:.3f}")


def demo_cabin_noise_sources(output_dir: Path):
    """Demonstrate different cabin noise sources."""

    print("\n" + "="*70)
    print("CABIN NOISE SOURCE ANALYSIS")
    print("="*70)

    duration = 3.0
    sample_rate = 44100

    # === Wind noise at different speeds ===
    print("\nWind Noise:")
    for speed_kmh in [50, 100, 130]:
        speed_ms = speed_kmh / 3.6  # Convert km/h to m/s
        print(f"  {speed_kmh} km/h ({speed_ms:.1f} m/s)")

        wind_noise = generate_wind_noise(
            velocity=speed_ms,
            turbulence_intensity=0.5,
            duration=duration,
            sample_rate=sample_rate
        )

        filename = output_dir / f"wind_noise_{speed_kmh}kmh.wav"
        io_storage.save_audio(str(filename), wind_noise.data, wind_noise.sample_rate)
        print(f"    Saved: {filename}")

    # === Road noise ===
    print("\nRoad Noise:")
    road_types = {
        "smooth_asphalt": 0.2,
        "normal_road": 0.5,
        "rough_road": 0.8
    }

    vehicle_speed = 100.0 / 3.6  # 100 km/h

    for road_name, roughness in road_types.items():
        print(f"  {road_name.replace('_', ' ').title()} (roughness={roughness:.1f})")

        road_noise = generate_road_noise(
            road_roughness=roughness,
            vehicle_speed=vehicle_speed,
            duration=duration,
            sample_rate=sample_rate
        )

        filename = output_dir / f"road_noise_{road_name}.wav"
        io_storage.save_audio(str(filename), road_noise.data, road_noise.sample_rate)
        print(f"    Saved: {filename}")

    # === Combined cabin noise ===
    print("\nCombined Cabin Noise (100 km/h, normal road):")

    wind = generate_wind_noise(100.0/3.6, 0.5, duration, sample_rate)
    road = generate_road_noise(0.5, 100.0/3.6, duration, sample_rate)

    # Mix: 60% road noise, 40% wind noise
    combined = 0.6 * road.data + 0.4 * wind.data

    # Normalize
    combined = combined / np.max(np.abs(combined))

    filename = output_dir / "combined_cabin_noise_100kmh.wav"
    io_storage.save_audio(str(filename), combined, sample_rate)
    print(f"  Saved: {filename}")


def main():
    """Run comprehensive automotive cabin acoustics demo."""

    print("\n" + "="*70)
    print("MORPHOGEN AUTOMOTIVE CABIN ACOUSTICS SHOWCASE")
    print("Fluid Dynamics â†’ Acoustics â†’ Audio Integration")
    print("="*70)

    # Create output directory
    output_dir = Path(__file__).parent / "output" / "automotive"
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"\nOutput directory: {output_dir}")

    # === DEMO 1: Speaker placement optimization ===
    demo_speaker_optimization(output_dir)

    # === DEMO 2: Cabin noise sources ===
    demo_cabin_noise_sources(output_dir)

    print("\n" + "="*70)
    print("DEMO COMPLETE!")
    print("="*70)
    print(f"\nGenerated {len(list(output_dir.glob('*.wav')))} audio files")
    print("\nKEY INSIGHTS:")
    print("  â€¢ Speaker placement significantly affects sound quality")
    print("  â€¢ Wind noise increases with velocity squared (aerodynamics)")
    print("  â€¢ Road noise depends on tire rotation and surface roughness")
    print("  â€¢ Cabin materials affect acoustic damping and reflections")
    print("\nThis physics-based approach enables:")
    print("  âœ“ Virtual acoustic prototyping before physical builds")
    print("  âœ“ Speaker system optimization ($$ premium audio)")
    print("  âœ“ NVH prediction and reduction (customer satisfaction)")
    print("  âœ“ Active noise cancellation design")
    print("\nðŸš— Automotive OEMs: This saves millions in prototyping! ðŸš—\n")


if __name__ == "__main__":
    main()
